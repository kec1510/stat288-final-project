{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yV9zPUkqTs54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6905975-d67f-4217-e5e4-94bf307b2cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtJ1DKlFVxXX",
        "outputId": "59eb089a-7533-4f99-f210-fc8778ac8a82"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.4.26)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.0.2)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.3)\n",
            "Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import rasterio\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- Config ---\n",
        "IMAGE_DIR = \"/content/drive/My Drive/HLS_Composite_Patches_2021\"\n",
        "LABEL_CSV = \"/content/drive/My Drive/HLS_Composite_Patches_2021/HLS_Patch_Labels_2021.csv\"\n",
        "IMG_SIZE = (256, 256)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "\n",
        "# --- 1. Load label mapping ---\n",
        "labels_df = pd.read_csv(LABEL_CSV)\n",
        "labels_dict = dict(zip(labels_df[\"fileNamePrefix\"], labels_df[\"label\"]))\n",
        "\n",
        "# --- 2. Collect image paths and match to labels ---\n",
        "all_image_paths = [os.path.join(IMAGE_DIR, f) for f in os.listdir(IMAGE_DIR) if f.endswith('.tif')]\n",
        "\n",
        "# Extract filename without extension to match CSV\n",
        "filtered_paths = [\n",
        "    p for p in all_image_paths\n",
        "    if os.path.splitext(os.path.basename(p))[0] in labels_dict\n",
        "]\n",
        "\n",
        "print(f\"Matched {len(filtered_paths)} images with labels.\")"
      ],
      "metadata": {
        "id": "wZoteMC9Uv7L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d0c78b-6820-4b73-e8e1-d3bc0e1e476e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matched 1650 images with labels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Split train/test ---\n",
        "train_paths, test_paths = train_test_split(filtered_paths, test_size=0.2, random_state=288)\n",
        "\n",
        "# --- 4. Load function: RGB image + scalar label ---\n",
        "def load_image_and_label(path):\n",
        "    path_str = path.decode()\n",
        "    with rasterio.open(path_str) as src:\n",
        "        img = src.read(out_shape=(3, *IMG_SIZE))  # (3, H, W)\n",
        "        img = np.transpose(img, (1, 2, 0))  # to (H, W, 3)\n",
        "        img = np.nan_to_num(img.astype(np.float32))\n",
        "\n",
        "    basename = os.path.splitext(os.path.basename(path_str))[0]\n",
        "    label = np.float32(labels_dict[basename])\n",
        "\n",
        "    return img, label\n",
        "\n",
        "# --- 5. Create tf.data.Dataset ---\n",
        "def create_dataset(paths, batch_size=BATCH_SIZE, shuffle=True):\n",
        "    def _parse(path):\n",
        "        image, label = tf.numpy_function(load_image_and_label, [path], [tf.float32, tf.float32])\n",
        "        image.set_shape([*IMG_SIZE, 3])\n",
        "        label.set_shape([])\n",
        "        return image, label\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices(paths)\n",
        "    ds = ds.map(_parse, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(100)\n",
        "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds"
      ],
      "metadata": {
        "id": "MMB_Fud4Jcs6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_ds = create_dataset(train_paths)\n",
        "test_ds = create_dataset(test_paths, shuffle=False)\n",
        "\n",
        "print(\"✅ Dataset ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mBEOhC0JizD",
        "outputId": "7224f027-e244-4c49-db29-7736ac410cb5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test image\n",
        "with rasterio.open(filtered_paths[0]) as src:\n",
        "    print(\"Dtype:\", src.dtypes)\n",
        "    raw = src.read(1)  # first band\n",
        "    print(\"Raw min/max:\", raw.min(), raw.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aELx6O8cUhBb",
        "outputId": "f8df06e2-83d0-4770-8f4b-3b8cd224f2b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dtype: ('float64', 'float64', 'float64')\n",
            "Raw min/max: -0.0026500000000000004 0.4601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_image_regression_model(input_shape=(256, 256, 3)):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    x = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    outputs = layers.Dense(1)(x)\n",
        "\n",
        "    return models.Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "i9Y5OygnVKhE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_image_regression_model()\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"best_model.keras\", save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=1e-6\n",
        "    )\n",
        "]\n",
        "\n",
        "# --- Compile ---\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, clipnorm=1.0),\n",
        "    loss=tf.keras.losses.MeanSquaredError(),\n",
        "    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        ")"
      ],
      "metadata": {
        "id": "iZ5NWALGVjck"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UPDATED IMAGE REG BASE MODEL\n",
        "history = model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUUZ1OvaV4MC",
        "outputId": "a9070ee7-2a28-487c-b814-d5378d001318"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 8s/step - loss: 875.6575 - root_mean_squared_error: 29.5609 - val_loss: 272.7048 - val_root_mean_squared_error: 16.5138 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 8s/step - loss: 184.5692 - root_mean_squared_error: 13.5469 - val_loss: 123.7397 - val_root_mean_squared_error: 11.1238 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 8s/step - loss: 137.4456 - root_mean_squared_error: 11.7149 - val_loss: 124.8257 - val_root_mean_squared_error: 11.1725 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 8s/step - loss: 134.9027 - root_mean_squared_error: 11.6109 - val_loss: 118.7033 - val_root_mean_squared_error: 10.8951 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 8s/step - loss: 136.3167 - root_mean_squared_error: 11.6638 - val_loss: 117.9212 - val_root_mean_squared_error: 10.8592 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 8s/step - loss: 130.6363 - root_mean_squared_error: 11.4232 - val_loss: 117.9891 - val_root_mean_squared_error: 10.8623 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 8s/step - loss: 132.0979 - root_mean_squared_error: 11.4852 - val_loss: 116.0628 - val_root_mean_squared_error: 10.7732 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 9s/step - loss: 127.4978 - root_mean_squared_error: 11.2896 - val_loss: 116.5763 - val_root_mean_squared_error: 10.7971 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 8s/step - loss: 128.5375 - root_mean_squared_error: 11.3347 - val_loss: 116.3019 - val_root_mean_squared_error: 10.7843 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 8s/step - loss: 130.0798 - root_mean_squared_error: 11.3992 - val_loss: 117.2018 - val_root_mean_squared_error: 10.8260 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 8s/step - loss: 128.8661 - root_mean_squared_error: 11.3445 - val_loss: 115.7626 - val_root_mean_squared_error: 10.7593 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 7s/step - loss: 127.3482 - root_mean_squared_error: 11.2810 - val_loss: 115.8810 - val_root_mean_squared_error: 10.7648 - learning_rate: 5.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 8s/step - loss: 127.3546 - root_mean_squared_error: 11.2780 - val_loss: 117.4636 - val_root_mean_squared_error: 10.8381 - learning_rate: 5.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 7s/step - loss: 125.5262 - root_mean_squared_error: 11.1921 - val_loss: 115.5766 - val_root_mean_squared_error: 10.7507 - learning_rate: 5.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 9s/step - loss: 124.0813 - root_mean_squared_error: 11.1370 - val_loss: 115.4760 - val_root_mean_squared_error: 10.7460 - learning_rate: 5.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 8s/step - loss: 123.0541 - root_mean_squared_error: 11.0914 - val_loss: 116.4382 - val_root_mean_squared_error: 10.7907 - learning_rate: 5.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 7s/step - loss: 126.5822 - root_mean_squared_error: 11.2458 - val_loss: 115.8465 - val_root_mean_squared_error: 10.7632 - learning_rate: 5.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 8s/step - loss: 126.2442 - root_mean_squared_error: 11.2315 - val_loss: 115.4088 - val_root_mean_squared_error: 10.7428 - learning_rate: 5.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 8s/step - loss: 124.4142 - root_mean_squared_error: 11.1506 - val_loss: 115.9206 - val_root_mean_squared_error: 10.7666 - learning_rate: 5.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 8s/step - loss: 122.3491 - root_mean_squared_error: 11.0581 - val_loss: 115.5658 - val_root_mean_squared_error: 10.7502 - learning_rate: 5.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 8s/step - loss: 122.2591 - root_mean_squared_error: 11.0553 - val_loss: 117.3624 - val_root_mean_squared_error: 10.8334 - learning_rate: 5.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 8s/step - loss: 124.9250 - root_mean_squared_error: 11.1716 - val_loss: 116.2824 - val_root_mean_squared_error: 10.7834 - learning_rate: 2.5000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 8s/step - loss: 127.5374 - root_mean_squared_error: 11.2792 - val_loss: 117.0343 - val_root_mean_squared_error: 10.8182 - learning_rate: 2.5000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, rmse = model.evaluate(test_ds)\n",
        "print(f\"Test RMSE: {rmse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-jD2duXWu0g",
        "outputId": "c879818e-a27a-4ad1-8082-c8ddd11fb970"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3s/step - loss: 115.5377 - root_mean_squared_error: 10.7377\n",
            "Test RMSE: 10.7428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_resnet50_regression_model(input_shape=(256, 256, 3)):\n",
        "    base = ResNet50(\n",
        "        input_shape=input_shape,\n",
        "        weights='imagenet',\n",
        "        include_top=False  # Remove ImageNet classifier head\n",
        "    )\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(base.output)\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    output = layers.Dense(1)(x)  # Single scalar output\n",
        "\n",
        "    model = models.Model(inputs=base.input, outputs=output)\n",
        "    return model"
      ],
      "metadata": {
        "id": "jWzu5F8TXUK9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=5, restore_best_weights=True),\n",
        "    ModelCheckpoint(\"best_model.keras\", save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=1e-6\n",
        "    )\n",
        "]\n",
        "\n",
        "model2 = build_resnet50_regression_model()\n",
        "\n",
        "# --- Compile ---\n",
        "model2.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4, clipnorm=1.0),\n",
        "    loss=tf.keras.losses.MeanSquaredError(),\n",
        "    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olcBbufaXV1J",
        "outputId": "feebeb7d-cdb0-4e72-ef0e-662609d73838"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history2 = model2.fit(train_ds, validation_data=test_ds, epochs=20, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_Ciou2EXeNA",
        "outputId": "6716a9ef-c1e9-417e-d5fb-87be6c8c8ed7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m624s\u001b[0m 7s/step - loss: 621.5468 - root_mean_squared_error: 24.7757 - val_loss: 698.0421 - val_root_mean_squared_error: 26.4205 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 3s/step - loss: 110.0967 - root_mean_squared_error: 10.4808 - val_loss: 195.7522 - val_root_mean_squared_error: 13.9911 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3s/step - loss: 60.7753 - root_mean_squared_error: 7.7936 - val_loss: 330.6154 - val_root_mean_squared_error: 18.1828 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 3s/step - loss: 62.1384 - root_mean_squared_error: 7.8713 - val_loss: 224.5216 - val_root_mean_squared_error: 14.9840 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 3s/step - loss: 48.1748 - root_mean_squared_error: 6.9384 - val_loss: 417.6788 - val_root_mean_squared_error: 20.4372 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 3s/step - loss: 48.0873 - root_mean_squared_error: 6.9056 - val_loss: 313.1019 - val_root_mean_squared_error: 17.6947 - learning_rate: 5.0000e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 3s/step - loss: 31.0161 - root_mean_squared_error: 5.5674 - val_loss: 172.4673 - val_root_mean_squared_error: 13.1327 - learning_rate: 5.0000e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3s/step - loss: 24.1153 - root_mean_squared_error: 4.9076 - val_loss: 200.7023 - val_root_mean_squared_error: 14.1669 - learning_rate: 5.0000e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 3s/step - loss: 24.4347 - root_mean_squared_error: 4.9423 - val_loss: 165.2369 - val_root_mean_squared_error: 12.8544 - learning_rate: 5.0000e-05\n",
            "Epoch 10/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 3s/step - loss: 21.8711 - root_mean_squared_error: 4.6646 - val_loss: 212.7411 - val_root_mean_squared_error: 14.5856 - learning_rate: 5.0000e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 3s/step - loss: 25.8728 - root_mean_squared_error: 5.0792 - val_loss: 152.9350 - val_root_mean_squared_error: 12.3667 - learning_rate: 5.0000e-05\n",
            "Epoch 12/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 3s/step - loss: 18.3773 - root_mean_squared_error: 4.2800 - val_loss: 148.9259 - val_root_mean_squared_error: 12.2035 - learning_rate: 5.0000e-05\n",
            "Epoch 13/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 3s/step - loss: 22.4336 - root_mean_squared_error: 4.7318 - val_loss: 146.2274 - val_root_mean_squared_error: 12.0925 - learning_rate: 5.0000e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 3s/step - loss: 18.7051 - root_mean_squared_error: 4.3226 - val_loss: 142.5350 - val_root_mean_squared_error: 11.9388 - learning_rate: 5.0000e-05\n",
            "Epoch 15/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 3s/step - loss: 19.9912 - root_mean_squared_error: 4.4591 - val_loss: 132.3096 - val_root_mean_squared_error: 11.5026 - learning_rate: 5.0000e-05\n",
            "Epoch 16/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 3s/step - loss: 16.9922 - root_mean_squared_error: 4.1178 - val_loss: 170.0134 - val_root_mean_squared_error: 13.0389 - learning_rate: 5.0000e-05\n",
            "Epoch 17/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - loss: 17.0014 - root_mean_squared_error: 4.1227 - val_loss: 150.7247 - val_root_mean_squared_error: 12.2770 - learning_rate: 5.0000e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 3s/step - loss: 18.0645 - root_mean_squared_error: 4.2445 - val_loss: 171.5910 - val_root_mean_squared_error: 13.0993 - learning_rate: 5.0000e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - loss: 20.5544 - root_mean_squared_error: 4.5202 - val_loss: 173.2658 - val_root_mean_squared_error: 13.1630 - learning_rate: 2.5000e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - loss: 13.5838 - root_mean_squared_error: 3.6831 - val_loss: 197.4147 - val_root_mean_squared_error: 14.0504 - learning_rate: 2.5000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, rmse = model2.evaluate(test_ds)\n",
        "print(f\"Test RMSE: {rmse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkfD_YWbXdAh",
        "outputId": "a13775cd-a60e-4316-f61b-c39adb8a40a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - loss: 135.1998 - root_mean_squared_error: 11.6215\n",
            "Test RMSE: 11.5026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NEW TEST DATASETS\n",
        "# --- Config ---\n",
        "LOWER_DIR = \"/content/drive/My Drive/HLS_Composite_Patches_2021_CRElower\"\n",
        "LOWER_LABEL_CSV = \"/content/drive/My Drive/HLS_Composite_Patches_2021_CRElower/HLS_Patch_Labels_2021_lower.csv\"\n",
        "\n",
        "UPPER_DIR = \"/content/drive/My Drive/HLS_Composite_Patches_2021_CREupper\"\n",
        "UPPER_LABEL_CSV = \"/content/drive/My Drive/HLS_Composite_Patches_2021_CREupper/HLS_Patch_Labels_2021_upper.csv\"\n",
        "\n",
        "\n",
        "def map_test_set(IMAGE_DIR, LABEL_CSV):\n",
        "\n",
        "  labels_df = pd.read_csv(LABEL_CSV)\n",
        "  labels_dict = dict(zip(labels_df[\"fileNamePrefix\"], labels_df[\"label\"]))\n",
        "\n",
        "  all_image_paths = [os.path.join(IMAGE_DIR, f) for f in os.listdir(IMAGE_DIR) if f.endswith('.tif')]\n",
        "\n",
        "  # Extract filename without extension to match CSV\n",
        "  filtered_paths = [\n",
        "      p for p in all_image_paths\n",
        "      if os.path.splitext(os.path.basename(p))[0] in labels_dict\n",
        "  ]\n",
        "  print(f\"Matched {len(filtered_paths)} images with labels.\")\n",
        "  return (filtered_paths, labels_dict)"
      ],
      "metadata": {
        "id": "KhYhthjWQgUo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_cre_lower = map_test_set(LOWER_DIR, LOWER_LABEL_CSV)\n",
        "lower_dict = test_cre_lower[1]\n",
        "test_cre_upper = map_test_set(UPPER_DIR, UPPER_LABEL_CSV)\n",
        "upper_dict = test_cre_upper[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wgy4wJMQxJV",
        "outputId": "7d972bcb-41c1-451f-8792-95a03bb2a76f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matched 50 images with labels.\n",
            "Matched 50 images with labels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_and_label(path):\n",
        "    path_str = path.decode()\n",
        "    with rasterio.open(path_str) as src:\n",
        "        img = src.read(out_shape=(3, *IMG_SIZE))  # (3, H, W)\n",
        "        img = np.transpose(img, (1, 2, 0))  # to (H, W, 3)\n",
        "        img = np.nan_to_num(img.astype(np.float32))\n",
        "\n",
        "    basename = os.path.splitext(os.path.basename(path_str))[0]\n",
        "    label = np.float32(upper_dict[basename])\n",
        "\n",
        "    return img, label\n",
        "\n",
        "def create_dataset(paths, batch_size=BATCH_SIZE, shuffle=True):\n",
        "    def _parse(path):\n",
        "        image, label = tf.numpy_function(load_image_and_label, [path], [tf.float32, tf.float32])\n",
        "        image.set_shape([*IMG_SIZE, 3])\n",
        "        label.set_shape([])\n",
        "        return image, label\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices(paths)\n",
        "    ds = ds.map(_parse, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(100)\n",
        "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds"
      ],
      "metadata": {
        "id": "tPhe0cD-849-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_lower = create_dataset(test_cre_lower[0], shuffle=False)\n",
        "# loss, rmse = model.evaluate(test_lower)\n",
        "# print(f\"Test RMSE (base model, lower bound): {rmse:.4f}\")"
      ],
      "metadata": {
        "id": "m-GeJD_cSDJy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_upper = create_dataset(test_cre_upper[0], shuffle=False)\n",
        "# loss, rmse = model.evaluate(test_upper)\n",
        "# print(f\"Test RMSE (base model, upper bound): {rmse:.4f}\")"
      ],
      "metadata": {
        "id": "c6S7goUuSPE2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, rmse = model.evaluate(test_upper)\n",
        "print(f\"Test RMSE (base model, upper bound): {rmse:.4f}\")"
      ],
      "metadata": {
        "id": "wNMYtQsmSTki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, rmse = model2.evaluate(test_lower)\n",
        "print(f\"Test RMSE (ResNet model, lower bound): {rmse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXhxza3DST7r",
        "outputId": "98b2216e-e3f5-4300-f76c-6c1695ac2499"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9s/step - loss: 232.6067 - root_mean_squared_error: 15.2490\n",
            "Test RMSE (ResNet model, lower bound): 15.0575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, rmse = model2.evaluate(test_upper)\n",
        "print(f\"Test RMSE (ResNet model, upper bound): {rmse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yy12xjfbSUOJ",
        "outputId": "a641e63c-ea97-4927-ef38-a3ec97cc6f08"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6s/step - loss: 62.1921 - root_mean_squared_error: 7.8669\n",
            "Test RMSE (ResNet model, upper bound): 8.2570\n"
          ]
        }
      ]
    }
  ]
}