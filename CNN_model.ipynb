{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yV9zPUkqTs54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f74931bc-686b-45b8-8d57-3eaa1f1abd9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtJ1DKlFVxXX",
        "outputId": "5835a42d-66be-45d4-eb44-cb921ffde548"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.4.26)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.0.2)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.3)\n",
            "Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import rasterio\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- Config ---\n",
        "IMAGE_DIR = \"/content/drive/My Drive/HLS_Composite_Patches_2021\"\n",
        "LABEL_CSV = \"/content/drive/My Drive/HLS_Composite_Patches_2021/HLS_Patch_Labels_2021.csv\"\n",
        "IMG_SIZE = (256, 256)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "\n",
        "# --- 1. Load label mapping ---\n",
        "labels_df = pd.read_csv(LABEL_CSV)\n",
        "labels_dict = dict(zip(labels_df[\"fileNamePrefix\"], labels_df[\"label\"]))\n",
        "\n",
        "# --- 2. Collect image paths and match to labels ---\n",
        "all_image_paths = [os.path.join(IMAGE_DIR, f) for f in os.listdir(IMAGE_DIR) if f.endswith('.tif')]\n",
        "\n",
        "# Extract filename without extension to match CSV\n",
        "filtered_paths = [\n",
        "    p for p in all_image_paths\n",
        "    if os.path.splitext(os.path.basename(p))[0] in labels_dict\n",
        "]\n",
        "\n",
        "print(f\"Matched {len(filtered_paths)} images with labels.\")"
      ],
      "metadata": {
        "id": "wZoteMC9Uv7L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "391df2a6-7546-4bde-e92d-c23eedc83179"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matched 1650 images with labels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Split train/test ---\n",
        "train_paths, test_paths = train_test_split(filtered_paths, test_size=0.2, random_state=288)\n",
        "\n",
        "# --- 4. Load function: RGB image + scalar label ---\n",
        "def load_image_and_label(path):\n",
        "    path_str = path.decode()\n",
        "    with rasterio.open(path_str) as src:\n",
        "        img = src.read(out_shape=(3, *IMG_SIZE))  # (3, H, W)\n",
        "        img = np.transpose(img, (1, 2, 0))  # to (H, W, 3)\n",
        "        img = np.nan_to_num(img.astype(np.float32))\n",
        "\n",
        "    basename = os.path.splitext(os.path.basename(path_str))[0]\n",
        "    label = np.float32(labels_dict[basename])\n",
        "\n",
        "    return img, label\n",
        "\n",
        "# --- 5. Create tf.data.Dataset ---\n",
        "def create_dataset(paths, batch_size=BATCH_SIZE, shuffle=True):\n",
        "    def _parse(path):\n",
        "        image, label = tf.numpy_function(load_image_and_label, [path], [tf.float32, tf.float32])\n",
        "        image.set_shape([*IMG_SIZE, 3])\n",
        "        label.set_shape([])\n",
        "        return image, label\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices(paths)\n",
        "    ds = ds.map(_parse, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(100)\n",
        "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds"
      ],
      "metadata": {
        "id": "MMB_Fud4Jcs6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_ds = create_dataset(train_paths)\n",
        "test_ds = create_dataset(test_paths, shuffle=False)\n",
        "\n",
        "print(\"✅ Dataset ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mBEOhC0JizD",
        "outputId": "ee8c47b4-a162-4a36-9c28-094e7432b908"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test image\n",
        "with rasterio.open(filtered_paths[0]) as src:\n",
        "    print(\"Dtype:\", src.dtypes)\n",
        "    raw = src.read(1)  # first band\n",
        "    print(\"Raw min/max:\", raw.min(), raw.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aELx6O8cUhBb",
        "outputId": "f8df06e2-83d0-4770-8f4b-3b8cd224f2b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dtype: ('float64', 'float64', 'float64')\n",
            "Raw min/max: -0.0026500000000000004 0.4601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_image_regression_model(input_shape=(256, 256, 3)):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    x = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    outputs = layers.Dense(1)(x)\n",
        "\n",
        "    return models.Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "i9Y5OygnVKhE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_image_regression_model()\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"best_model.keras\", save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=1e-6\n",
        "    )\n",
        "]\n",
        "\n",
        "# --- Compile ---\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, clipnorm=1.0),\n",
        "    loss=tf.keras.losses.MeanSquaredError(),\n",
        "    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        ")"
      ],
      "metadata": {
        "id": "iZ5NWALGVjck"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UPDATED IMAGE REG BASE MODEL\n",
        "history = model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUUZ1OvaV4MC",
        "outputId": "a9070ee7-2a28-487c-b814-d5378d001318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 8s/step - loss: 875.6575 - root_mean_squared_error: 29.5609 - val_loss: 272.7048 - val_root_mean_squared_error: 16.5138 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 8s/step - loss: 184.5692 - root_mean_squared_error: 13.5469 - val_loss: 123.7397 - val_root_mean_squared_error: 11.1238 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m 3/42\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:27\u001b[0m 7s/step - loss: 149.9756 - root_mean_squared_error: 12.2004"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, rmse = model.evaluate(test_ds)\n",
        "print(f\"Test RMSE: {rmse:.4f}\")"
      ],
      "metadata": {
        "id": "e-jD2duXWu0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_resnet50_regression_model(input_shape=(256, 256, 3)):\n",
        "    base = ResNet50(\n",
        "        input_shape=input_shape,\n",
        "        weights='imagenet',\n",
        "        include_top=False  # Remove ImageNet classifier head\n",
        "    )\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(base.output)\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    output = layers.Dense(1)(x)  # Single scalar output\n",
        "\n",
        "    model = models.Model(inputs=base.input, outputs=output)\n",
        "    return model"
      ],
      "metadata": {
        "id": "jWzu5F8TXUK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=7, restore_best_weights=True),\n",
        "    ModelCheckpoint(\"best_model.keras\", save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',1\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=1e-6\n",
        "    )\n",
        "]\n",
        "\n",
        "model2 = build_resnet50_regression_model()\n",
        "\n",
        "# --- Compile ---\n",
        "model2.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4, clipnorm=1.0),\n",
        "    loss=tf.keras.losses.MeanSquaredError(),\n",
        "    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        ")"
      ],
      "metadata": {
        "id": "olcBbufaXV1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history2 = model2.fit(train_ds, validation_data=test_ds, epochs=EPOCHS, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "q_Ciou2EXeNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, rmse = model2.evaluate(test_ds)\n",
        "print(f\"Test RMSE: {rmse:.4f}\")"
      ],
      "metadata": {
        "id": "jkfD_YWbXdAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# Take a batch from test set\n",
        "# for images, labels in test_ds.take(1):\n",
        "#     preds = model2.predict(images)\n",
        "\n",
        "#     # Plot predictions vs. ground truth\n",
        "#     for i in range(len(images)):\n",
        "#         img = images[i].numpy()\n",
        "#         label = labels[i].numpy()\n",
        "#         pred = preds[i][0]  # shape: (batch_size, 1)\n",
        "\n",
        "#         # Normalize image for display (only for visualization)\n",
        "#         img_disp = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
        "\n",
        "#         plt.figure(figsize=(5, 5))\n",
        "#         plt.imshow(img_disp)\n",
        "#         plt.title(f\"Predicted: {pred:.3f} | True: {label:.3f}\")\n",
        "#         plt.axis('off')\n",
        "#         plt.show()"
      ],
      "metadata": {
        "id": "80x8IJmUh0dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for images, labels in test_ds:\n",
        "#     preds = model2.predict(images)\n",
        "#     for i in range(len(images)):\n",
        "#         img = images[i].numpy()\n",
        "#         label = labels[i].numpy()\n",
        "#         pred = preds[i][0]  # shape: (batch_size, 1)\n",
        "#         print(pred, label)\n"
      ],
      "metadata": {
        "id": "FW3tYLoAlfdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def plot_training_curves(history):\n",
        "#     plt.figure(figsize=(10, 5))\n",
        "\n",
        "#     # Plot loss\n",
        "#     plt.subplot(1, 2, 1)\n",
        "#     plt.plot(history.history['loss'], label='Train Loss')\n",
        "#     plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "#     plt.xlabel('Epoch')\n",
        "#     plt.ylabel('MSE Loss')\n",
        "#     plt.title('Training & Validation Loss')\n",
        "#     plt.legend()\n",
        "\n",
        "#     # Plot RMSE\n",
        "#     if 'rmse' in history.history:\n",
        "#         plt.subplot(1, 2, 2)\n",
        "#         plt.plot(history.history['rmse'], label='Train RMSE')\n",
        "#         plt.plot(history.history['val_rmse'], label='Val RMSE')\n",
        "#         plt.xlabel('Epoch')\n",
        "#         plt.ylabel('RMSE')\n",
        "#         plt.title('Training & Validation RMSE')\n",
        "#         plt.legend()\n",
        "\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()"
      ],
      "metadata": {
        "id": "8t1G7NDDlPC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot_training_curves(history)"
      ],
      "metadata": {
        "id": "yM7ROwrbCsgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot_training_curves(history2)"
      ],
      "metadata": {
        "id": "HCOAvePnlSjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NEW TEST DATASETS\n",
        "# --- Config ---\n",
        "LOWER_DIR = \"/content/drive/My Drive/HLS_Composite_Patches_2021_CRElower\"\n",
        "LOWER_LABEL_CSV = \"/content/drive/My Drive/HLS_Composite_Patches_2021/HLS_Patch_Labels_2021_lower.csv\"\n",
        "\n",
        "UPPER_DIR = \"/content/drive/My Drive/HLS_Composite_Patches_2021_CREupper\"\n",
        "UPPER_LABEL_CSV = \"/content/drive/My Drive/HLS_Composite_Patches_2021/HLS_Patch_Labels_2021_upper.csv\"\n",
        "\n",
        "\n",
        "def map_test_set(IMAGE_DIR, LABEL_CSV):\n",
        "\n",
        "  labels_df = pd.read_csv(LABEL_CSV)\n",
        "  labels_dict = dict(zip(labels_df[\"fileNamePrefix\"], labels_df[\"label\"]))\n",
        "\n",
        "  all_image_paths = [os.path.join(IMAGE_DIR, f) for f in os.listdir(IMAGE_DIR) if f.endswith('.tif')]\n",
        "\n",
        "  # Extract filename without extension to match CSV\n",
        "  filtered_paths = [\n",
        "      p for p in all_image_paths\n",
        "      if os.path.splitext(os.path.basename(p))[0] in labels_dict\n",
        "  ]\n",
        "  print(f\"Matched {len(filtered_paths)} images with labels.\")\n",
        "  return filtered_paths\n",
        "\n"
      ],
      "metadata": {
        "id": "KhYhthjWQgUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_cre_lower = map_test_set(LOWER_DIR, LOWER_LABEL_CSV)\n",
        "test_cre_upper = map_test_set(UPPER_DIR, UPPER_LABEL_CSV)"
      ],
      "metadata": {
        "id": "2wgy4wJMQxJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_lower = create_dataset(test_cre_lower, shuffle=False)\n",
        "test_upper = create_dataset(test_cre_upper, shuffle=False)"
      ],
      "metadata": {
        "id": "m-GeJD_cSDJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, rmse = model.evaluate(test_lower)\n",
        "print(f\"Test RMSE (base model, lower bound): {rmse:.4f}\")"
      ],
      "metadata": {
        "id": "c6S7goUuSPE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, rmse = model.evaluate(test_upper)\n",
        "print(f\"Test RMSE (base model, upper bound): {rmse:.4f}\")"
      ],
      "metadata": {
        "id": "wNMYtQsmSTki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, rmse = model2.evaluate(test_lower)\n",
        "print(f\"Test RMSE (ResNet model, lower bound): {rmse:.4f}\")"
      ],
      "metadata": {
        "id": "EXhxza3DST7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, rmse = model2.evaluate(test_upper)\n",
        "print(f\"Test RMSE (ResNet model, upper bound): {rmse:.4f}\")"
      ],
      "metadata": {
        "id": "yy12xjfbSUOJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}